{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9a6653-0435-4d19-904e-7d52a996cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, year, month\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, FloatType, TimestampType, MapType\n",
    "from pyspark.sql.types import DoubleType\n",
    "import happybase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9a7615-6a82-4d92-89dd-3a3219769b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e22e49-5bd9-46b9-94c6-3bb924d7fbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08a91d2-0d35-49e0-b4f4-47702ba1c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaStreamingExample\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.8\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234263ab-9a12-46b2-866b-10527ce331b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers = \"\"\n",
    "kafka_topic = \"\"\n",
    "kafka_username = \"\"\n",
    "kafka_password = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6935dd-3ae6-44b5-b6a6-98385e491bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType() \\\n",
    "    .add(\"eventType\", StringType()) \\\n",
    "    .add(\"customerId\", StringType()) \\\n",
    "    .add(\"productId\", StringType()) \\\n",
    "    .add(\"timestamp\", TimestampType()) \\\n",
    "    .add(\"metadata\", StructType()\n",
    "        .add(\"category\", StringType())\n",
    "        .add(\"source\", StringType())\n",
    "    ) \\\n",
    "    .add(\"quantity\", IntegerType()) \\\n",
    "    .add(\"totalAmount\", DoubleType()) \\\n",
    "    .add(\"paymentMethod\", StringType()) \\\n",
    "    .add(\"recommendedProductId\", StringType()) \\\n",
    "    .add(\"algorithm\", StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12576910-e9df-4568-b441-e4b56f8ef70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", bootstrap_servers) \\\n",
    "    .option(\"subscribe\", kafka_topic) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"kafka.security.protocol\", \"SASL_SSL\") \\\n",
    "    .option(\"kafka.sasl.mechanism\", \"PLAIN\") \\\n",
    "    .option(\"kafka.sasl.jaas.config\",\n",
    "            f'org.apache.kafka.common.security.plain.PlainLoginModule required username=\"{kafka_username}\" password=\"{kafka_password}\";') \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b4783f-cb40-4795-a86e-c9a6d1c9c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df = df.selectExpr(\"CAST(value AS STRING)\").select(from_json(\"value\", schema).alias(\"data\")).select(\"data.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff0254c-dcb6-4a5f-b25a-d22d6b1fcad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = json_df \\\n",
    "    .withColumn(\"timestamp\", col(\"timestamp\").cast(TimestampType())) \\\n",
    "    .withColumn(\"year\", year(col(\"timestamp\"))) \\\n",
    "    .withColumn(\"month\", month(col(\"timestamp\"))) \\\n",
    "    .withColumn(\"category\", col(\"metadata\").getItem(\"category\")) \\\n",
    "    .withColumn(\"source\", col(\"metadata\").getItem(\"source\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358a1d23-e134-4998-9dcd-21cc250a86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_hbase(df, namespace, table_name, thrift_server, port=9090, batch_size=10):\n",
    "    print(f\"Starting to write data to HBase table: {namespace}:{table_name}\")\n",
    "    \n",
    "    try:\n",
    "        connection = happybase.Connection(thrift_server, port=port)\n",
    "        print(f\"connected to HBase at {thrift_server}:{port}\")\n",
    "        \n",
    "        table = connection.table(f'{namespace}:{table_name}')\n",
    "        print(f\"Accessing table: {namespace}:{table_name}\")\n",
    "        \n",
    "        tables = connection.tables()\n",
    "        print(f\"Available tables: {tables}\")\n",
    "        \n",
    "        batch = table.batch(batch_size=batch_size)\n",
    "        row_count = 0\n",
    "        \n",
    "        for row in df.collect():\n",
    "            try:\n",
    "                row_key = str(row['customerId'])\n",
    "                \n",
    "                \n",
    "                event_data = {\n",
    "                    'event_info:eventType': str(row['eventType']),\n",
    "                    'event_info:timestamp': str(row['timestamp'])\n",
    "                }\n",
    "                \n",
    "                transaction_data = {\n",
    "                    'transaction_data:productId': str(row['productId']) if row['productId'] is not None else '',\n",
    "                    'transaction_data:quantity': str(row['quantity']) if row['quantity'] is not None else '',\n",
    "                    'transaction_data:totalAmount': str(row['totalAmount']) if row['totalAmount'] is not None else '',\n",
    "                    'transaction_data:paymentMethod': str(row['paymentMethod']) if row['paymentMethod'] is not None else '',\n",
    "                    'transaction_data:recommendedProductId': str(row['recommendedProductId']) if row['recommendedProductId'] is not None else '',\n",
    "                    'transaction_data:algorithm': str(row['algorithm']) if row['algorithm'] is not None else ''\n",
    "                }\n",
    "                \n",
    "                \n",
    "                all_data = {**event_data, **{k: v for k, v in transaction_data.items() if v}}\n",
    "                \n",
    "                \n",
    "                batch.put(row_key, all_data)\n",
    "                \n",
    "                row_count += 1\n",
    "                if row_count % batch_size == 0:\n",
    "                    batch.send()\n",
    "                    print(f\"sent batch of {batch_size} rows. total rows: {row_count}\")\n",
    "                    batch = table.batch(batch_size=batch_size)\n",
    "            \n",
    "            except Exception as row_error:\n",
    "                print(f\"processing row: {str(row_error)}\")\n",
    "                print(f\"error: {row}\")\n",
    "        \n",
    "        \n",
    "        if row_count % batch_size != 0:\n",
    "            batch.send()\n",
    "            print(f\"Sent final batch. Total rows written: {row_count}\")\n",
    "        \n",
    "        return row_count\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to HBase: {str(e)}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac970be-dccc-4b36-9a42-a630d3629b54",
   "metadata": {},
   "outputs": [],
   "source": [
    " def process_batch(df, epoch_id):\n",
    "     try:\n",
    "         rows_written = write_to_hbase(df, 'streaming','events', 'hbase-thrift')\n",
    "         print(f\"Batch processed. Epoch ID: {epoch_id}, Rows written: {rows_written}\")\n",
    "     except Exception as e:\n",
    "         print(f\"Error processing batch: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a88325-c57d-4699-a979-b10a553b3731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent batch of 10 rows. Total rows so far: 10\n",
      "Sent batch of 10 rows. Total rows so far: 20\n",
      "Batch processed. Epoch ID: 493, Rows written: 20\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 5\n",
      "Batch processed. Epoch ID: 494, Rows written: 5\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 495, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 496, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 497, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 498, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 499, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 2\n",
      "Batch processed. Epoch ID: 500, Rows written: 2\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 501, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 502, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 503, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 504, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 505, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 506, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 507, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 508, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 509, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 510, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 511, Rows written: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d9dee9ed880f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpointLocation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hdfs://localhost:9000//user/streaming_check\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark2/python/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark2/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark2/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark2/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 512, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 513, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 514, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 2\n",
      "Batch processed. Epoch ID: 515, Rows written: 2\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 516, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 517, Rows written: 1\n",
      "Starting to write data to HBase table: streaming:events\n",
      "Successfully connected to HBase at hbase-thrift:9090\n",
      "Accessing table: streaming:events\n",
      "Available tables: [b'streaming:events']\n",
      "Sent final batch. Total rows written: 1\n",
      "Batch processed. Epoch ID: 518, Rows written: 1\n"
     ]
    }
   ],
   "source": [
    " query = transformed_df \\\n",
    "     .writeStream \\\n",
    "     .foreachBatch(process_batch) \\\n",
    "     .outputMode(\"append\") \\\n",
    "     .option(\"checkpointLocation\", \"hdfs://localhost:9000//user/streaming_check\") \\\n",
    "     .start()\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d157cf-0211-4fc4-bdcc-953fd797f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = transformed_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\", \"hdfs://localhost:9000//user/streaming\") \\\n",
    "    .option(\"checkpointLocation\", \"hdfs://localhost:9000//user/streaming_check\") \\\n",
    "    .start()\n",
    "\n",
    "#query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ee8cda2-f9f4-4115-8be1-2830e31a7426",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = spark.read.parquet(\"/user/streaming/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41b6f538-846b-45f8-93de-690d480e4316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+---------+-------------------+--------------------+--------+-----------+-------------+--------------------+--------------------+----+-----+--------------+------+\n",
      "|          eventType|customerId|productId|          timestamp|            metadata|quantity|totalAmount|paymentMethod|recommendedProductId|           algorithm|year|month|      category|source|\n",
      "+-------------------+----------+---------+-------------------+--------------------+--------+-----------+-------------+--------------------+--------------------+----+-----+--------------+------+\n",
      "|        productView|     63267|     4231|2024-07-28 05:27:45|     [Books, Direct]|    null|       null|         null|                null|                null|2024|    7|         Books|Direct|\n",
      "|          addToCart|     45129|     8421|2024-07-28 05:27:47|                 [,]|       1|       null|         null|                null|                null|2024|    7|          null|  null|\n",
      "|recommendationClick|     93263|     9790|2024-07-28 05:27:48|                 [,]|    null|       null|         null|                1134|       content_based|2024|    7|          null|  null|\n",
      "|          addToCart|     22865|     5180|2024-07-28 05:27:51|                 [,]|       3|       null|         null|                null|                null|2024|    7|          null|  null|\n",
      "|           purchase|     84258|     5728|2024-07-28 05:27:54|                 [,]|       1|     494.39|       PayPal|                null|                null|2024|    7|          null|  null|\n",
      "|          addToCart|     58858|     2835|2024-07-28 05:27:56|                 [,]|       5|       null|         null|                null|                null|2024|    7|          null|  null|\n",
      "|           purchase|     67817|     2919|2024-07-28 05:27:59|                 [,]|       3|     300.89|   Debit Card|                null|                null|2024|    7|          null|  null|\n",
      "|          addToCart|     86098|     8447|2024-07-28 05:28:02|                 [,]|       1|       null|         null|                null|                null|2024|    7|          null|  null|\n",
      "|          addToCart|     94122|     5832|2024-07-28 05:28:03|                 [,]|       4|       null|         null|                null|                null|2024|    7|          null|  null|\n",
      "|           purchase|     15147|     3086|2024-07-28 05:28:04|                 [,]|       3|     162.93|       PayPal|                null|                null|2024|    7|          null|  null|\n",
      "|recommendationClick|     27657|     8066|2024-07-28 05:28:10|                 [,]|    null|       null|         null|                7291|collaborative_fil...|2024|    7|          null|  null|\n",
      "|          addToCart|     37451|     3937|2024-07-28 05:38:06|                 [,]|       4|       null|         null|                null|                null|2024|    7|          null|  null|\n",
      "|        productView|     23726|     9625|2024-07-28 05:38:10|  [Clothing, Search]|    null|       null|         null|                null|                null|2024|    7|      Clothing|Search|\n",
      "|           purchase|     34710|     2677|2024-07-28 05:38:13|                 [,]|       1|     387.84|   Debit Card|                null|                null|2024|    7|          null|  null|\n",
      "|          addToCart|     75925|     2784|2024-07-28 05:38:15|                 [,]|       5|       null|         null|                null|                null|2024|    7|          null|  null|\n",
      "|          addToCart|     41224|     9964|2024-07-28 05:38:18|                 [,]|       3|       null|         null|                null|                null|2024|    7|          null|  null|\n",
      "|           purchase|     35100|     1309|2024-07-28 05:38:19|                 [,]|       5|     319.87|   Debit Card|                null|                null|2024|    7|          null|  null|\n",
      "|        productView|     46554|     6233|2024-07-28 05:38:21|[Home & Kitchen, ...|    null|       null|         null|                null|                null|2024|    7|Home & Kitchen|Search|\n",
      "|           purchase|     80244|     3779|2024-07-28 05:38:24|                 [,]|       1|     394.05|   Debit Card|                null|                null|2024|    7|          null|  null|\n",
      "|          addToCart|     31783|     5954|2024-07-28 05:38:27|                 [,]|       1|       null|         null|                null|                null|2024|    7|          null|  null|\n",
      "+-------------------+----------+---------+-------------------+--------------------+--------+-----------+-------------+--------------------+--------------------+----+-----+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "streaming_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2b360-a1d4-4465-ab0c-d8a6bb5497d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab8f2f-b876-462c-a85b-28c092f28373",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    productId, \n",
    "    SUM(totalAmount) as total_sales \n",
    "FROM \n",
    "    streaming_data \n",
    "GROUP BY \n",
    "    productId \n",
    "ORDER BY \n",
    "    total_sales DESC \n",
    "LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570a849-7654-4bd6-bc69-4a5ad55e7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    metadata.category, \n",
    "    YEAR('timestamp') as year, \n",
    "    MONTH('timestamp') as month, \n",
    "    SUM(totalAmount) as total_sales, \n",
    "    SUM(quantity) as total_quantity \n",
    "FROM \n",
    "    streaming_data \n",
    "GROUP BY \n",
    "    metadata.category, \n",
    "    YEAR('timestamp'), \n",
    "    MONTH('timestamp') \n",
    "ORDER BY \n",
    "    year, \n",
    "    month, \n",
    "    metadata.category;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e39d5a-9835-4024-8c84-412d308a8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df.write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option(\"path\",\"/user/streaming/*.parquet\")\\\n",
    "    .saveAsTable(\"default.streaming_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9e035e1-5ee6-447e-9dec-521bc8b4aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e35e7-6407-4ddb-9a3e-0b226ea6425a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
